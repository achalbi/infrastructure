# Reference documentation: https://opentelemetry.io/docs/platforms/kubernetes/getting-started/

# OpenTelemetry Collector values
mode: deployment  # deployment or daemonset (daemonset is for kubernetes)   

# We only want one of these collectors - any more and we'd produce duplicate data
replicaCount: 1

# presets:
#   # enables the k8sclusterreceiver and adds it to the metrics pipelines
#   clusterMetrics:
#     enabled: true
#   # enables the k8sobjectsreceiver to collect events only and adds it to the logs pipelines
#   kubernetesEvents:
#     enabled: true

# OpenTelemetry Collector configuration
config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: "0.0.0.0:4317"
        http:
          endpoint: "0.0.0.0:4318"
  processors:
    batch:
      timeout: 1s
      send_batch_size: 1024
    memory_limiter:
      check_interval: 1s
      limit_mib: 900
    attributes:
      actions:
        - key: log.file.name
          action: delete
        - key: log.file.path
          action: delete
    # transform:
    #   metric_statements:
    #     - context: datapoint
    #       statements:
    #         - 'set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])'
    #         - 'set(attributes["k8s.namespace.name"], resource.attributes["k8s.namespace.name"])'
    #         - 'set(attributes["k8s.deployment.name"], resource.attributes["k8s.deployment.name"])'
    #         - 'set(attributes["k8s.container.name"], resource.attributes["k8s.container.name"])'
    #         - 'set(attributes["k8s.node.name"], resource.attributes["k8s.node.name"])'
    #         - 'set(attributes["app.kubernetes.io/name"], resource.attributes["app.kubernetes.io/name"])'
    #         - 'set(attributes["app.kubernetes.io/instance"], resource.attributes["app.kubernetes.io/instance"])'
    #         - 'set(attributes["k8s.cluster.name"], resource.attributes["k8s.cluster.name"])'
    #         - 'set(attributes["container.id"], resource.attributes["container.id"])'
    resource:
      attributes:
        - key: k8s.pod.name
          from_attribute: k8s.pod.name
          action: insert
        - key: k8s.namespace.name
          from_attribute: k8s.namespace.name
          action: insert
        - key: k8s.deployment.name
          from_attribute: k8s.deployment.name
          action: insert
        - key: k8s.container.name
          from_attribute: k8s.container.name
          action: insert
        - key: k8s.node.name
          from_attribute: k8s.node.name
          action: insert
        - key: app.kubernetes.io/name
          from_attribute: app.kubernetes.io/name
          action: insert
        - key: app.kubernetes.io/instance
          from_attribute: app.kubernetes.io/instance
          action: insert
        - key: k8s.cluster.name
          from_attribute: k8s.cluster.name
          action: insert
        - key: container.id
          action: delete
    # resourcedetection:
    #   detectors: [env, system, eks]
    #   timeout: 5s
    #   override: false
  exporters:
    # debug: to be not present in production value file
    debug:
      verbosity: detailed
    otlphttp/loki:
      endpoint: http://loki-gateway.observability:80/otlp
    #    otlp/jaeger:
    #      endpoint: http://jaeger-collector:4317
    #      tls:
    #        insecure: true
    otlp/tempo:
      endpoint: tempo.observability:4317
      tls:
        insecure: true
    # Data sources: metrics
    prometheus:
      endpoint: 0.0.0.0:9464

    # Prometheus Remote Write Exporter sends OpenTelemetry metrics to Prometheus remote write compatible backends such as Cortex, Mimir, and Thanos.
    prometheusremotewrite:
      #      endpoint: http://prometheus.example.com:9411/api/prom/push
      #      # When using the official Prometheus (running via Docker)
      endpoint: 'http://prometheus-prometheus:9090/api/v1/write'
            # Convert remaining resource attributes to labels
      resource_to_telemetry_conversion:
        enabled: true
      target_info:
        enabled: true
      tls:
        insecure: true
  service:
    pipelines:
      traces:
        receivers: [ otlp ]
        processors: [ batch, memory_limiter ]
        exporters: [  otlp/tempo ]
        # exporters: [ spanmetrics, otlp/tempo,  debug ]
      metrics:
        # receivers: [ otlp, spanmetrics ]
        receivers: [ otlp ]
        processors: [ batch, memory_limiter, resource]
        exporters: [ prometheusremotewrite, debug ]
      logs:
        receivers: [ otlp]
        processors: [ attributes, memory_limiter ]
        exporters: [ otlphttp/loki ]

resources:
  limits:
    memory: 1Gi
  requests:
    cpu: 100m

image:
  repository: otel/opentelemetry-collector-contrib
  pullPolicy: Always

fullnameOverride: "opentelemetry-collector"

service:
  type: NodePort

ports:
  otlp:
    enabled: true
    containerPort: 4317
    servicePort: 4317
    hostPort: 4317
    protocol: TCP
    nodePort: 30317
    appProtocol: grpc
  otlp-http:
    enabled: true
    containerPort: 4318
    servicePort: 4318
    hostPort: 4318
    nodePort: 30318
    protocol: TCP
  prometheus:
    enabled: true
    containerPort: 9464
    servicePort: 9464
    hostPort: 9464
    protocol: TCP
    nodePort: 30464  # Choose an available NodePort
# ingress:
#   enabled: true
#   ingressClassName: nginx
#   hosts:
#     - host: otel-collector.telemetrix.in
#       paths:
#         - path: /
#           pathType: Prefix
#           port: 4318


serviceMonitor:
   # The service monitor by default scrapes the metrics port.
  # The metrics port needs to be enabled as well.
  enabled: true
  metricsEndpoints:
    - port: metrics
      interval: 15s
      path: /metrics
  # additional labels for the ServiceMonitor
  extraLabels:
    prometheus: prometheus-prometheus